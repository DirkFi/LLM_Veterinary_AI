{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will experiment with how user queries are handled in our veterinary information retrieval system. Several collections have already been set up in the Chroma database, allowing us to directly perform information retrieval without additional setup. This environment enables us to test and refine the process of transforming user input into actionable queries and retrieving relevant information from our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "persist_directory = '../chroma/textbook_test_Nutrition'\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "open_clip_embeddings = OpenCLIPEmbeddings(model_name=\"ViT-g-14\", checkpoint=\"laion2b_s34b_b88k\")\n",
    "\n",
    "# Vectorstore for summaries (for similarity search)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=open_clip_embeddings\n",
    ")\n",
    "# Persistent docstore for originals (all modalities)\n",
    "docstore = Chroma(\n",
    "    collection_name=\"originals\",\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=open_clip_embeddings\n",
    ")\n",
    "\n",
    "# Instantiate the retriever\n",
    "\n",
    "class UnifiedRetriever:\n",
    "        \n",
    "        def __init__(self, vectorstore, docstore, id_key=\"doc_id\"):\n",
    "            self.vectorstore = vectorstore\n",
    "            self.docstore = docstore\n",
    "            self.id_key = id_key\n",
    "            self._collection = docstore._collection\n",
    "\n",
    "        def retrieve(self, query, k=5):\n",
    "            results = self.vectorstore.similarity_search_with_score(query, k=k)\n",
    "            output = []\n",
    "            for doc, score in results:\n",
    "                doc_id = doc.metadata.get(self.id_key)\n",
    "                try:\n",
    "                    original = self._collection.get(ids=[doc_id], include=[\"documents\", \"metadatas\"])\n",
    "                    original_doc = original[\"documents\"][0] if original[\"documents\"] else None\n",
    "                    original_meta = original[\"metadatas\"][0] if original[\"metadatas\"] else None\n",
    "                except Exception as e:\n",
    "                    original_doc = None\n",
    "                    original_meta = None\n",
    "                output.append({\n",
    "                    \"summary\": doc.page_content,\n",
    "                    \"original\": original_doc,\n",
    "                    \"original_metadata\": original_meta,\n",
    "                    \"summary_metadata\": doc.metadata,\n",
    "                    \"score\": score\n",
    "                })\n",
    "            return output\n",
    "\n",
    "retriever = UnifiedRetriever(vectorstore, docstore, id_key=id_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling User Input: Analysis Image\n",
    "\n",
    "Let's use a image of a under weighted cat. This cat is considerablly skinny with bones showing. \n",
    "\n",
    "  ![Skinney Cat](./skinny_cat.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⏳ Processing image: ./skinny_cat.jpg\n",
      "--- Generated Image Summary ---\n",
      "The image depicts a cat standing next to a bowl of water, with its head resting on the edge of the bowl. The cat is positioned on a tiled floor, facing the camera, and appears to be in a state of poor health.\n",
      "\n",
      "* **Cat**\n",
      "\t+ The cat is light-colored, with a pale yellowish-white coat.\n",
      "\t+ It has a thin and emaciated appearance, with visible ribs and a prominent spine.\n",
      "\t+ Its eyes are yellowish-green, and its ears are pointed and erect.\n",
      "\t+ The cat's fur is matted and unkempt, with visible signs of neglect.\n",
      "* **Bowl**\n",
      "\t+ The bowl is light green and appears to be made of plastic.\n",
      "\t+ It is placed on the floor next to the cat, with the cat's head resting on the edge.\n",
      "\t+ The bowl is empty, with no water visible inside.\n",
      "* **Floor**\n",
      "\t+ The floor is made of small, square tiles that are a light brown color.\n",
      "\t+ The tiles are arranged in a grid pattern, with a slight grout line between each tile.\n",
      "\t+ The floor appears to be dirty, with visible dust and dirt particles.\n",
      "\n",
      "Overall, the image suggests that the cat is in a state of poor health, with visible signs of neglect and malnutrition. The empty bowl and dirty floor further support this conclusion. It is likely that the cat is in need of medical attention and care.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's going on with my cat? What should I do?\" \n",
    "image_path = \"./skinny_cat.jpg\"\n",
    "\n",
    "import base64\n",
    "import ollama\n",
    "import os\n",
    "\n",
    "# --- Configuration for the image ---\n",
    "# IMPORTANT: Adjust this path if your cat.jpg is in a different location\n",
    "# image_model = \"minicpm-v:8b\" # Or \"llava:7b\" or another suitable vision model you have installed via Ollama\n",
    "# image_model = \"llava:7b\" # \n",
    "\n",
    "#This instruct version, q8_0 weight format fits MacBook M1 Pro better\n",
    "image_model = \"llama3.2-vision:11b-instruct-q4_K_M\" # \n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Generate a textual summary of the image using an LLM ---\n",
    "print(f\" ⏳ Processing image: {image_path}\")\n",
    "\n",
    "image_summary = \"Could not generate image summary.\" # Default in case of error\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"Error: Image file not found at {image_path}. Please check the path.\")\n",
    "else:\n",
    "    try:\n",
    "        # Read and encode image in base64\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "        # Updated prompt for detailed image summarization\n",
    "        image_summarization_prompt = \"\"\"From a feline veterinary stand point, provide a highly detailed and objective \n",
    "                description of the image. Focus on all observable elements, actions, \n",
    "                objects, subjects, their attributes (e.g., color, size, texture), \n",
    "                their spatial relationships, and any discernible context or implied scene. \n",
    "                Also focus on all possible health issue.\n",
    "                Describe any text present in the image. This description must be exhaustive \n",
    "                and purely factual, capturing every significant visual detail to serve as a \n",
    "                comprehensive textual representation for further analysis by another AI model. \n",
    "                If the image is entirely irrelevant or contains no discernible subject, \n",
    "                state \"No relevant visual information.\".\"\"\"\n",
    "\n",
    "        # Send image to ollama for vision model processing\n",
    "        response = ollama.chat(\n",
    "            model=image_model,\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': image_summarization_prompt,\n",
    "                    'images': [image_data]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        image_summary = response['message']['content']\n",
    "        print(\"--- Generated Image Summary ---\")\n",
    "        print(image_summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image with Ollama: {e}\")\n",
    "\n",
    "# This 'image_summary' can now be used along with your user's text query\n",
    "# for retrieval or further processing in your RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling User Input: Refine Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Refined query: Refined Query:\n",
      "\n",
      "\"I'm concerned about my light-colored, pale yellowish-white domestic shorthair cat's health, as indicated by its thin and emaciated appearance, visible ribs, prominent spine, yellowish-green eyes, pointed and erect ears, matted and unkempt fur, and signs of neglect. The cat is positioned on a tiled floor with small, square tiles in a grid pattern, made of light brown material, which appears dirty with visible dust and dirt particles. Notably, the cat's food bowl, made of light green plastic, is empty and placed next to the cat, with no water visible inside. Given these visual cues, I would like to know:\n",
      "\n",
      "1. What are the possible causes of my cat's poor health, malnutrition, and signs of neglect?\n",
      "2. What steps can I take immediately to ensure my cat's immediate needs are met, such as providing food, water, and shelter?\n",
      "3. Are there any specific veterinary conditions or diseases that may be contributing to my cat's condition?\n",
      "4. How often should I feed my cat, and what type of food would be most suitable for its nutritional needs?\n",
      "5. What are the signs of dehydration in cats, and how can I ensure my cat is getting enough water?\n",
      "6. Are there any additional resources or support services available to help me care for my cat, such as local animal welfare organizations or low-cost veterinary clinics?\n",
      "\n",
      "I'm seeking guidance on how to address my cat's immediate needs and provide the necessary care to prevent further health complications.\"\n",
      "\n",
      "This refined query incorporates relevant keywords from the image description, clarifies the user's intent, and anticipates related information that might be helpful. It covers a range of potential topics, including the causes of the cat's condition, steps for immediate care, veterinary conditions or diseases, nutritional needs, dehydration signs, and resources for support.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define the LLM for query refinement (using the same model as your RAG chain if appropriate)\n",
    "# Compressed, Distilled Qwen, Response often in CoT <think></think>\n",
    "# query_refinement_model = ChatOllama(model=\"deepseek-r1:7b-qwen-distill-q8_0\")\n",
    "\n",
    "#compressed that fits m1 pro, use less RAM. No CoT\n",
    "query_refinement_model = ChatOllama(model=\"llama3.2:3b\")\n",
    "\n",
    "# Prompt for query refinement\n",
    "query_refinement_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an intelligent assistant. Your task is to rephrase and expand the given user query \\\n",
    "into a more detailed and context-rich query that can be used to retrieve relevant information \\\n",
    "from a veterinary knowledge base. Use the provided image description to add visual context \\\n",
    "and relevant keywords to the refined query. Focus on adding relevant keywords, clarifying intent, \\\n",
    "and anticipating related information that might be helpful. The output should be a single, refined query.\n",
    "\n",
    "Original query: {original_query}\n",
    "Image description: {image_summary}\"\"\"\n",
    ")\n",
    "\n",
    "# Create the query refinement chain\n",
    "query_refinement_chain = (\n",
    "    {\n",
    "        \"original_query\": RunnablePassthrough(),\n",
    "        \"image_summary\": RunnablePassthrough()\n",
    "    }\n",
    "    | query_refinement_prompt\n",
    "    | query_refinement_model\n",
    "    | StrOutputParser()\n",
    ")# --- Demonstration of query refinement and then retrieval with scores ---\n",
    "\n",
    "# print(f\"Original user query: {query}\")\n",
    "# print(f\"Image Summary: {image_summary}\")\n",
    "\n",
    "refined_query = query_refinement_chain.invoke(\n",
    "    {\"original_query\": query, \"image_summary\": image_summary}\n",
    ")\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"Refined query: {refined_query}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original refined query: Refined Query:\n",
      "\n",
      "\"I'm concerned about my light-colored, pale yellowish-white domestic shorthair cat's health, as indicated by its thin and emaciated appearance, visible ribs, prominent spine, yellowish-green eyes, pointed and erect ears, matted and unkempt fur, and signs of neglect. The cat is positi ....\n",
      "--------------------------------------------------------------------------------\n",
      "There are 6 queries after decomposition \n",
      "\n",
      "Here's a example of the first one: What are the possible causes of thin and emaciated domestic shorthair cats?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "# Prompt for query decomposition\n",
    "query_decomposition_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an intelligent assistant. Your task is to break down the given complex query\n",
    "into a list of simpler, focused sub-queries. Each sub-query should be a standalone question\n",
    "that can be used to retrieve specific information from a veterinary knowledge base.\n",
    "\n",
    "Output ONLY a valid JSON array of strings, and nothing else. Do not include any explanations, markdown, or extra text.\n",
    "\n",
    "Complex query: {refined_query}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the query decomposition chain\n",
    "query_decomposition_chain = (\n",
    "    query_decomposition_prompt  \n",
    "    | query_refinement_model    \n",
    "    | JsonOutputParser() \n",
    ")\n",
    "\n",
    "# --- Demonstration of query decomposition ---\n",
    "\n",
    "print(f\"Original refined query: {refined_query[:300]} ....\")\n",
    "\n",
    "decomposed_queries = query_decomposition_chain.invoke({\"refined_query\": refined_query})\n",
    "\n",
    "print(\"-\" * 80)\n",
    "# print(f\"Decomposed queries:\\n{decomposed_queries}\")\n",
    "\n",
    "print(f\"There are {len(decomposed_queries)} queries after decomposition \\n\")\n",
    "print(f\"Here's a example of the first one: {decomposed_queries[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Retrievals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:backoff:Backing off send_request(...) for 0.6s (requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique documents retrieved: 10\n",
      "Total queries with at least one unique result: 4\n",
      "Number of unique documents retrieved per query:\n",
      "  Query: What are the possible causes of thin and emaciated domestic ... -> 5 unique docs\n",
      "  Query: How to provide food, water, and shelter to malnourished dome... -> 1 unique docs\n",
      "  Query: Common veterinary conditions or diseases affecting domestic ... -> 3 unique docs\n",
      "  Query: Signs of dehydration in domestic shorthair cats... -> 1 unique docs\n"
     ]
    }
   ],
   "source": [
    "# Assume decomposed_queries is a list of query strings\n",
    "# and retriever is already instantiated\n",
    "\n",
    "seen_doc_ids = set()\n",
    "all_results = []\n",
    "\n",
    "for query in decomposed_queries:\n",
    "    results = retriever.retrieve(query, k=5)\n",
    "    unique_results = []\n",
    "    for res in results:\n",
    "        doc_id = res.get('doc_id') or res.get('summary_metadata', {}).get('doc_id')\n",
    "        if doc_id and doc_id not in seen_doc_ids:\n",
    "            seen_doc_ids.add(doc_id)\n",
    "            unique_results.append(res)\n",
    "    if unique_results:\n",
    "        all_results.append({\n",
    "            \"query\": query,\n",
    "            \"results\": unique_results\n",
    "        })\n",
    "\n",
    "# Summarize all_results\n",
    "total_unique_docs = sum(len(entry['results']) for entry in all_results)\n",
    "total_queries_with_results = len(all_results)\n",
    "all_doc_ids = set()\n",
    "for entry in all_results:\n",
    "    for res in entry['results']:\n",
    "        doc_id = res.get('doc_id') or res.get('summary_metadata', {}).get('doc_id')\n",
    "        if doc_id:\n",
    "            all_doc_ids.add(doc_id)\n",
    "\n",
    "print(f\"Total unique documents retrieved: {len(all_doc_ids)}\")\n",
    "print(f\"Total queries with at least one unique result: {total_queries_with_results}\")\n",
    "print(\"Number of unique documents retrieved per query:\")\n",
    "for entry in all_results:\n",
    "    print(f\"  Query: {entry['query'][:60]}... -> {len(entry['results'])} unique docs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly Answering Query with Retrieved Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer:\n",
      "Here's a thorough and concise response as a veterinary assistant:\n",
      "\n",
      "1. **Main Issue:** The main issue observed in the image summary is the cat's poor health, with visible signs of neglect and malnutrition. The cat appears thin and emaciated, with visible ribs and a prominent spine, indicating potential malnutrition or starvation.\n",
      "\n",
      "2. **Possible Cause:** Based on the provided context, it seems likely that the cat's diet has been inadequate or lacking in essential nutrients. The fact that the bowl is empty and the floor is dirty suggests that the cat may not have access to clean water or food for an extended period. Additionally, the presence of mats and unkempt fur indicates a lack of proper grooming and hygiene.\n",
      "\n",
      "3. **Solution:** To solve this main issue, it would be essential to provide the cat with a nutritious diet that meets its protein and nutrient requirements. This may involve switching to a high-quality premium brand cat food that has a higher meat content and fewer grains than popular brands. It's also crucial to ensure access to clean water at all times.\n",
      "\n",
      "Considering the cat's poor health, it would be best to consult with a veterinarian for personalized advice on diet and care. The vet can assess the cat's overall health and provide guidance on the most suitable diet and treatment plan.\n",
      "\n",
      "In the meantime, providing the following basic needs could help alleviate the cat's immediate suffering:\n",
      "\n",
      "* Offer fresh water in an easily accessible bowl.\n",
      "* Feed a nutrient-rich, balanced commercial cat food that meets the cat's nutritional requirements.\n",
      "* Provide a clean, safe environment with proper litter facilities.\n",
      "* Consider taking the cat to a veterinary clinic for medical attention and treatment.\n",
      "\n",
      "Remember, every cat is unique, so monitoring food intake and adjusting based on activity level and metabolic rate is crucial. Consulting with a veterinarian will help ensure that any dietary changes or treatment plans are tailored to the individual needs of this cat.\n"
     ]
    }
   ],
   "source": [
    "# Combine all summaries from all_results into one context\n",
    "all_context = \"\\n\".join(\n",
    "    res['summary']\n",
    "    for entry in all_results\n",
    "    for res in entry['results']\n",
    ")\n",
    "\n",
    "\n",
    "final_answer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful veterinary assistant. Use the provided context to answer the \n",
    "    user's question as thoroughly and concisely as possible. Follow the following steps\n",
    "    when giving an prompt answer to the user.\n",
    "    1. Describe what was the main issue that you observed from the image summary?\n",
    "    2. What could be the cause of the main issue?\n",
    "    3. How can this main issue be solved?\n",
    "\n",
    "    User's question: {query}\n",
    "\n",
    "    Image Summary: {image_summary}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Answer:\"\"\"\n",
    "    )\n",
    "\n",
    "final_answer_chain = (\n",
    "    final_answer_prompt\n",
    "    | ChatOllama(model=\"llama3.2:3b\")  \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_answer = final_answer_chain.invoke({\n",
    "    \"query\": query,\n",
    "    \"image_summary\": image_summary,\n",
    "    \"context\": all_context\n",
    "})\n",
    "\n",
    "print(\"Final Answer:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling Chain of Thought Way To Answer Query\n",
    "\n",
    "Previously, We used llama3.2:3b model to answer the query with image summary and retrieved info giving to it. However, the answer can be incomprehensive and missing the target. Here we will try to use reasoning model that outputs chain of thought(CoT) that can solve this issue. For example:\n",
    "1. deepseek-r1 7b 8b \n",
    "2. qwen3 4b 8b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have model to think of a plan to answer query that helps user to understand the cause, \n",
    "# possible underlying issue, recommended next steps, etc.\n",
    "\n",
    "# If context not enough, fetch info on Wikipedia, or use Tavily\n",
    "\n",
    "# Let it pause and think, what info gap is there? Does it need more info from the owner? \n",
    "# i.e. \"is vaccine up-to-date?\", \"is eating and drinking ok?\", \"is pooping and peeing ok?\",..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
