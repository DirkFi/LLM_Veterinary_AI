{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will experiment with how user queries are handled in our veterinary information retrieval system. Several collections have already been set up in the Chroma database, allowing us to directly perform information retrieval without additional setup. This environment enables us to test and refine the process of transforming user input into actionable queries and retrieving relevant information from our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "# from langchain.storage import InMemoryStore # Removed for direct Chroma inspection\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "\n",
    "persist_directory = '../chroma/textbook_test_Nutrition'\n",
    "#persist_directory = '../chroma/textbook_test_parasites'\n",
    "id_key = \"doc_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling User Input: Analysis Image\n",
    "\n",
    "Let's use a image of a under weighted cat. This cat is considerablly skinny with bones showing. \n",
    "\n",
    "  ![Skinney Cat](./skinny_cat.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⏳ Processing image: ./skinny_cat.jpg\n",
      "--- Generated Image Summary ---\n",
      "The image depicts an adult cat with light-colored fur standing on terracotta-tiled flooring. The feline appears to be a domestic short-haired breed and has a collar around its neck adorned with what seems like bells or tags near the base of the tail, which is visible in profile. Its ears are perked up, indicating alertness.\n",
      "\n",
      "The cat's head is turned towards a green plastic bowl placed on the ground slightly behind it; however, it does not seem to be drinking from it at this moment as its mouth is closed and facing away from the water source. The bowl appears clean with some scattered small debris or food particles around its rim.\n",
      "\n",
      "In the background, there's an open door leading into a dimly lit area that could possibly be indoors, suggesting that this scene might take place in a transitional space between inside and outside of a building. There are also partial views of what appear to be metal objects and perhaps some greenery or another animal partially visible at the top edge of the image.\n",
      "\n",
      "There is no discernible text present within the frame of the photo. The overall context suggests that this cat may be waiting for its meal or has just finished eating, given the proximity to the water bowl typically associated with feeding times in domestic cats.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's going on with my cat? What should I do?\" \n",
    "image_path = \"./skinny_cat.jpg\"\n",
    "\n",
    "import base64\n",
    "import ollama # Ensure ollama library is installed (pip install ollama)\n",
    "\n",
    "# --- Configuration for the image ---\n",
    "# IMPORTANT: Adjust this path if your cat.jpg is in a different location\n",
    "image_model = \"minicpm-v:8b\" # Or \"llava:7b\" or another suitable vision model you have installed via Ollama\n",
    "\n",
    "# --- 1. Generate a textual summary of the image using an LLM ---\n",
    "print(f\" ⏳ Processing image: {image_path}\")\n",
    "\n",
    "image_summary = \"Could not generate image summary.\" # Default in case of error\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"Error: Image file not found at {image_path}. Please check the path.\")\n",
    "else:\n",
    "    try:\n",
    "        # Read and encode image in base64\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "        # Updated prompt for detailed image summarization\n",
    "        image_summarization_prompt = \"\"\"From a feline veterinary stand point, provide a highly detailed and objective \n",
    "                description of the image. Focus on all observable elements, actions, \n",
    "                objects, subjects, their attributes (e.g., color, size, texture), \n",
    "                their spatial relationships, and any discernible context or implied scene. \n",
    "                Describe any text present in the image. This description must be exhaustive \n",
    "                and purely factual, capturing every significant visual detail to serve as a \n",
    "                comprehensive textual representation for further analysis by another AI model. \n",
    "                If the image is entirely irrelevant or contains no discernible subject, \n",
    "                state \"No relevant visual information.\".\"\"\"\n",
    "\n",
    "        # Send image to ollama for vision model processing\n",
    "        response = ollama.chat(\n",
    "            model=image_model,\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': image_summarization_prompt,\n",
    "                    'images': [image_data]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        image_summary = response['message']['content']\n",
    "        print(\"--- Generated Image Summary ---\")\n",
    "        print(image_summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image with Ollama: {e}\")\n",
    "\n",
    "# This 'image_summary' can now be used along with your user's text query\n",
    "# for retrieval or further processing in your RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling User Input: Refine Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original user query: What's going on with my cat? What should I do?\n",
      "Image Summary: The image depicts an adult cat with light-colored fur standing on terracotta-tiled flooring. The feline appears to be a domestic short-haired breed and has a collar around its neck adorned with what seems like bells or tags near the base of the tail, which is visible in profile. Its ears are perked up, indicating alertness.\n",
      "\n",
      "The cat's head is turned towards a green plastic bowl placed on the ground slightly behind it; however, it does not seem to be drinking from it at this moment as its mouth is closed and facing away from the water source. The bowl appears clean with some scattered small debris or food particles around its rim.\n",
      "\n",
      "In the background, there's an open door leading into a dimly lit area that could possibly be indoors, suggesting that this scene might take place in a transitional space between inside and outside of a building. There are also partial views of what appear to be metal objects and perhaps some greenery or another animal partially visible at the top edge of the image.\n",
      "\n",
      "There is no discernible text present within the frame of the photo. The overall context suggests that this cat may be waiting for its meal or has just finished eating, given the proximity to the water bowl typically associated with feeding times in domestic cats.\n",
      "--------------------------------------------------------------------------------\n",
      "Refined query: Based on the provided query and image description, I've rephrased and expanded it into a more detailed and context-rich query:\n",
      "\n",
      "**Refined Query:**\n",
      "\n",
      "\"What appears to be the symptoms or potential health issues of my [light-colored domestic short-haired] cat, given its behavior in the photo? Specifically, considering the cat's perked-up ears, proximity to an empty water bowl, and the presence of scattered food particles, what possible explanations could there be for this cat's condition? Are there any common medical conditions or behavioral issues that might cause a cat to wait near a full food bowl without drinking from it? I'm also curious about potential reasons why my cat may have its collar adorned with bells or tags near the base of the tail. Are these accessories related to identification, health monitoring, or perhaps some other purpose? Could this scene be indicative of a transitional space between indoors and outdoors, such as a screened-in porch or a catio? What are the possible implications for my cat's nutrition, hydration, and overall well-being in this environment?\"\n",
      "\n",
      "**Anticipated Related Information:**\n",
      "\n",
      "* Common health issues related to food and water bowl behavior\n",
      "* Potential causes for a cat's collar having bells or tags near the base of the tail (identification, health monitoring, etc.)\n",
      "* Nutritional considerations for cats waiting near full food bowls without drinking from them\n",
      "* Health implications of transitional spaces between indoors and outdoors on feline nutrition and hydration\n",
      "* Behavioral patterns and potential explanations for perked-up ears in domestic short-haired cats\n",
      "\n",
      "**Additional Context:**\n",
      "\n",
      "The image description provides a clear visual representation of the scene, with the cat standing on terracotta-tiled flooring, its collar adorned with bells or tags near the base of the tail, and its head turned towards an empty water bowl. The background suggests a transitional space between indoors and outdoors, with partial views of metal objects and greenery visible at the top edge of the image.\n",
      "\n",
      "This refined query captures the user's concerns about their cat's behavior and overall health, while also exploring potential explanations for the observed symptoms and considering related factors that might impact the cat's well-being.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Define the LLM for query refinement (using the same model as your RAG chain if appropriate)\n",
    "query_refinement_model = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Prompt for query refinement\n",
    "query_refinement_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an intelligent assistant. Your task is to rephrase and expand the given user query \\\n",
    "into a more detailed and context-rich query that can be used to retrieve relevant information \\\n",
    "from a veterinary knowledge base. Use the provided image description to add visual context \\\n",
    "and relevant keywords to the refined query. Focus on adding relevant keywords, clarifying intent, \\\n",
    "and anticipating related information that might be helpful. The output should be a single, refined query.\n",
    "\n",
    "Original query: {original_query}\n",
    "Image description: {image_summary}\"\"\"\n",
    ")\n",
    "\n",
    "# Create the query refinement chain\n",
    "query_refinement_chain = (\n",
    "    {\n",
    "        \"original_query\": RunnablePassthrough(),\n",
    "        \"image_summary\": RunnablePassthrough()\n",
    "    }\n",
    "    | query_refinement_prompt\n",
    "    | query_refinement_model\n",
    "    | StrOutputParser()\n",
    ")# --- Demonstration of query refinement and then retrieval with scores ---\n",
    "\n",
    "\n",
    "print(f\"Original user query: {query}\")\n",
    "print(f\"Image Summary: {image_summary}\")\n",
    "\n",
    "refined_query = query_refinement_chain.invoke(\n",
    "    {\"original_query\": query, \"image_summary\": image_summary}\n",
    ")\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"Refined query: {refined_query}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original refined query: Refined Query:\n",
      "\n",
      "\"I'm concerned about my adult cat's sudden distress and possible illness, characterized by matted fur around its neck and chest, wide open eyes indicating alertness, anxiety, or discomfort, and perked-up ears. The cat's coat displays brown, black, and white patches. I'd like to know  ....\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"What are the possible medical causes of matted fur around my adult cat's neck and chest?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "# Prompt for query decomposition\n",
    "query_decomposition_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an intelligent assistant. Your task is to break down the given complex query \\\n",
    "into a list of simpler, focused sub-queries. Each sub-query should be a standalone question \\\n",
    "that can be used to retrieve specific information from a veterinary knowledge base. \\\n",
    "Present the sub-queries as a JSON array of strings, where each string is a sub-query. \\\n",
    "\n",
    "Complex query: {refined_query}\"\"\"\n",
    ")\n",
    "\n",
    "# Create the query decomposition chain\n",
    "query_decomposition_chain = (\n",
    "    query_decomposition_prompt  \n",
    "    | query_refinement_model    \n",
    "    | JsonOutputParser() \n",
    ")\n",
    "\n",
    "# --- Demonstration of query decomposition ---\n",
    "\n",
    "print(f\"Original refined query: {refined_query[:300]} ....\")\n",
    "\n",
    "decomposed_queries = query_decomposition_chain.invoke({\"refined_query\": refined_query})\n",
    "\n",
    "print(\"-\" * 80)\n",
    "# print(f\"Decomposed queries:\\n{decomposed_queries}\")\n",
    "\n",
    "decomposed_queries[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
