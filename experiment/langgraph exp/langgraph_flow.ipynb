{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LangSmith API\n",
    "Retrievals can be traced here for easier debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGSMITH_API_KEY'] = ' tryurbest-2-guess-what-it_i5* '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class VetAssistantState:\n",
    "    text_query: str\n",
    "    image: Optional[Any] = None  # e.g., file path, URL, or bytes\n",
    "    image_summary: Optional[str] = None\n",
    "    triage_result: Optional[str] = None\n",
    "    conversation_history: List[Dict[str, str]] = field(default_factory=list)  # [{'role': 'user', 'content': ...}, ...]\n",
    "    clarification_needed: bool = False\n",
    "    clarification_question: Optional[str] = None\n",
    "    clarification_answer: Optional[str] = None\n",
    "    retrieved_docs: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    final_answer: Optional[str] = None\n",
    "    citations: List[str] = field(default_factory=list)\n",
    "    web_search_results: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    path_taken: List[str] = field(default_factory=list)\n",
    "    symptom_list: List[str] = field(default_factory=list)\n",
    "    follow_up_count: int = 0\n",
    "    error: Optional[str] = None\n",
    "    awaiting_user_feedback: bool = False\n",
    "    current_probe: Optional[str] = None  \n",
    "    probe_result: Optional[str] = None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Graph Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Triage Router Node</h3>\n",
    "\n",
    "Classifies user intent: 'emergency', 'symptom_check', or 'general_qa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "triage_prompt = PromptTemplate(\n",
    "    template=\n",
    "    \"You are a veterinary assistant triage system. \"\n",
    "    \"Classify the following user input into one of three categories: \"\n",
    "    \"'emergency', 'symptom_check', or 'general_qa'.\\n\\n\"\n",
    "    \"User text input: {text_query}\\n\"\n",
    "    \"{image_block}\"\n",
    "    \"\\nRespond strictly with only one word: emergency, symptom_check, or general_qa.\"\n",
    "    ,\n",
    "    input_variables=[\"text_query\", \"image_block\"]\n",
    ")\n",
    "\n",
    "triage_router = triage_prompt | ChatOllama(model=\"llama3.2:3b\", temperature=0.0) | StrOutputParser()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
